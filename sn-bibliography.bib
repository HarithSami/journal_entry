@article{arai2021developments,
  author = "Arai, T. and Khatib, O. and Brock, O. and others",
  title = "Developments and Future Prospects of Collaborative Robotics",
  journal = "Annual Reviews in Control",
  pages = "389--409",
  year = "2021"
}

@inproceedings{benjamin2007cognitive,
  author = "Benjamin, D.P. and Lonsdale, Deryle and Lyons, Damian M.",
  title = "A cognitive robotics approach to comprehending human language and behaviors",
  booktitle = "Proceedings of the ACM/IEEE international conference on Human-robot interaction",
  year = "2007",
  url = "https://dl.acm.org/citation.cfm?doid=1228716.1228742"
}

@article{bohr2020intelligent,
  author = "Bohr, A. and Memarzadeh, M.",
  title = "Intelligent Assistive Systems: A Paradigm for Bridging the Gap Between Robotics and Healthcare",
  journal = "IEEE Robotics and Automation Letters",
  pages = "5331--5338",
  year = "2020"
}

@article{brohan2023rt2,
  author = "Brohan, A.",
  title = "RT-2: Vision-language-action models transfer web knowledge to robotic control",
  journal = "arXiv preprint arXiv:2307.15818v1",
  year = "2023"
}

@inproceedings{bruyninckx2001open,
  author = "Bruyninckx, H.",
  title = "Open Robot Control Software: the OROCOS project",
  booktitle = "Proceedings of IEEE International Conference on Robotics and Automation",
  pages = "2523--2528",
  year = "2001"
}

@article{cavalieri2015combining,
  author = "Cavalieri, Daniel Cruz and Bastos-Filho, Teodiano and Palazuelos-Cagigas, Sira E. and Sarcinelli-Filho, Mario",
  title = "On Combining Language Models to Improve a Text-based Human-machine Interface",
  journal = "International Journal of Advanced Robotic Systems",
  volume = "12",
  number = "12",
  pages = "170",
  year = "2015"
}

@article{chen2022self,
  author = "Chen, G. and Karlovsky, L. and Wang, Y. and others",
  title = "Self-Instruct: Socratic Instruction Tuning with Self-Supervision",
  journal = "arXiv preprint arXiv:2212.10560",
  year = "2022"
}

@inproceedings{conway2005goal,
  author = "Conway, C. and Higley, P. and Jacopin, E.",
  title = "Goal-Oriented Action Planning: Ten Years Old and No Fear!",
  year = "2005"
}

@article{cui2011astar,
  author = "Cui, X. and Shi, H.",
  title = "A*-based Pathfinding in Modern Computer Games",
  journal = "IJCSNS International Journal of Computer Science and Network Security",
  pages = "125--131",
  year = "2011"
}

@inproceedings{fraser2018spoken,
  author = "Fraser, Jamie and Papaioannou, Ioannis and Lemon, Oliver",
  title = "Spoken Conversational AI in Video Games: Emotional Dialogue Management Increases User Engagement",
  year = "2018",
  url = "https://dl.acm.org/citation.cfm?id=3267896"
}

@article{google2023open,
  author = "{Google DeepMind}",
  title = "Open X-Embodiment: Robotic Learning Datasets and RT-X Models",
  journal = "arXiv preprint arXiv:2310.08864",
  year = "2023"
}
@inproceedings{inproceedings,
author = {Hämäläinen, Perttu and Tavast, Mikke and Kunnari, Anton},
year = {2023},
month = {04},
pages = {1-19},
title = {Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study},
doi = {10.1145/3544548.3580688}
}
@article{hri-article,
author = {Goodrich, Michael and Schultz, Alan},
year = {2007},
month = {01},
pages = {203-275},
title = {Human-Robot Interaction: A Survey},
volume = {1},
journal = {Foundations and Trends in Human-Computer Interaction},
doi = {10.1561/1100000005}
}
@inproceedings{10.1145/3610977.3634966,
author = {Kim, Callie Y. and Lee, Christine P. and Mutlu, Bilge},
title = {Understanding Large-Language Model (LLM)-powered Human-Robot Interaction},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634966},
doi = {10.1145/3610977.3634966},
abstract = {Large-language models (LLMs) hold significant promise in improving human-robot interaction, offering advanced conversational skills and versatility in managing diverse, open-ended user requests in various tasks and domains. Despite the potential to transform human-robot interaction, very little is known about the distinctive design requirements for utilizing LLMs in robots, which may differ from text and voice interaction and vary by task and context. To better understand these requirements, we conducted a user study (n = 32) comparing an LLM-powered social robot against text- and voice-based agents, analyzing task-based requirements in conversational tasks, including choose, generate, execute, and negotiate. Our findings show that LLM-powered robots elevate expectations for sophisticated non-verbal cues and excel in connection-building and deliberation, but fall short in logical communication and may induce anxiety. We provide design implications both for robots integrating LLMs and for fine-tuning LLMs for use with robots.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {371–380},
numpages = {10},
keywords = {human-robot interaction, large language models, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}
@inproceedings{kruijff2007incremental,
  title={Incremental, multi-level processing for comprehending situated dialogue in human-robot interaction},
  author={Kruijff, Geert-Jan M and Lison, Pierre and Benjamin, Trevor and Jacobsson, Henrik and Hawes, Nick},
  booktitle={Symposium on Language and Robots},
  year={2007}
}
@inproceedings{hamalainen2023evaluating,
  author = "Hämäläinen, P. and Tavast, M. and Kunnari, A.",
  title = "Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study",
  year = "2023",
  url = "https://dl.acm.org/doi/fullHtml/10.1145/3544548.3580688"
}

@techreport{ibrahim2024scoping,
  author = "Ibrahim, H.S.",
  title = "Scoping and Planning Document: Robot Planning Enhanced using Decision Trees and LLMs (Large language models)",
  institution = "University of Leeds",
  pages = "2--3",
  year = "2024"
}

@article{iovino2022survey,
  author = "Iovino, M. and Scukins, E. and Styrud, J. and others",
  title = "A survey of Behavior Trees in robotics and AI",
  journal = "Robotics and Autonomous Systems",
  pages = "104096",
  year = "2022"
}

@article{jiang2022vima,
  author = "Jiang, Y. and He, D. and Kapelyukh, L. and others",
  title = "VIMA: General Robot Manipulation with Multimodal Prompts",
  journal = "arXiv preprint arXiv:2210.03094",
  year = "2022"
}

@article{JIANG2022100869,
title = {Developing a genre-based model for assessing digital multimodal composing in second language writing: Integrating theory with practice},
journal = {Journal of Second Language Writing},
volume = {57},
pages = {100869},
year = {2022},
note = {L2 writing assessment in the digital age},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2022.100869},
url = {https://www.sciencedirect.com/science/article/pii/S1060374322000029},
author = {Lianjiang Jiang and Shulin Yu and Icy Lee},
keywords = {Digital multimodal composing, Writing assessment, Genre-based model, Writing instruction},
abstract = {While previous research on digital multimodal composing (DMC) has examined the efficacy of either an element-based rubric or a process-based model that assesses students’ DMC across stages, the important notion of genre and its value for DMC assessment remains underexplored and undertheorized. Given that as a new literacy practice in L2 writing and related fields, DMC covers a wide range of genres, a genre-based model that incorporates the composing elements and process for assessing DMC is warranted. Driven by theories of genre and multimodality, the study first proposed a multilayered framework that entails DMC structures, functions, modal features and selections. Then the theory-driven framework was tested and modified through collaborative action research with five teachers of a university English for general and academic purposes course in China. The study then drew on student-authored multimodal compositions, interviews and observations with the teachers in order to explore how the teachers assessed DMC, as well as the challenges they encountered. Based on the findings, a refined genre-based model that guides teachers to evaluate DMC as purpose-directed social actions to be constructed with apt multimodal choices within and across four major layers (i.e., base units, layout, navigation, and rhetoric) was developed, with implications discussed.}
}
@article{kothari2023game,
  author = "Kothari, R. and Rathod, J. and Shah, A. and others",
  title = "Game Development using Artificial Intelligence in Unreal Engine",
  journal = "RJET",
  pages = "4361--4367",
  year = "2023"
}

@article{koyama2022study,
  author = "Koyama, K. and Ueda, S. and Kiyono, S. and others",
  title = "A study on safe interaction with large language models by combining classical task and motion planning",
  journal = "arXiv preprint arXiv:2208.11989",
  year = "2022"
}

@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@article{annurev:/content/journals/10.1146/annurev-control-082619-100135,
   author = "Karpas, Erez and Magazzeni, Daniele",
   title = "Automated Planning for Robotics", 
   journal= "Annual Review of Control, Robotics, and Autonomous Systems",
   year = "2020",
   volume = "3",
   number = "Volume 3, 2020",
   pages = "417-439",
   doi = "https://doi.org/10.1146/annurev-control-082619-100135",
   url = "https://www.annualreviews.org/content/journals/10.1146/annurev-control-082619-100135",
   publisher = "Annual Reviews",
   issn = "2573-5144",
   type = "Journal Article",
   keywords = "artificial intelligence",
   keywords = "automated planning",
   keywords = "robotics",
   keywords = "AI planning",
   abstract = "Modern robots are increasingly capable of performing “basic” activities such as localization, navigation, and motion planning. However, for a robot to be considered intelligent, we would like it to be able to automatically combine these capabilities in order to achieve a high-level goal. The field of automated planning (sometimes called AI planning) deals with automatically synthesizing plans that combine basic actions to achieve a high-level goal. In this article, we focus on the intersection of automated planning and robotics and discuss some of the challenges and tools available to employ automated planning in controlling robots. We review different types of planning formalisms and discuss their advantages and limitations, especially in the context of planning robot actions. We conclude with a brief guide aimed at helping roboticists choose the right planning model to endow a robot with planning capabilities.",
  }


@misc{singh2022progpromptgeneratingsituatedrobot,
      title={ProgPrompt: Generating Situated Robot Task Plans using Large Language Models}, 
      author={Ishika Singh and Valts Blukis and Arsalan Mousavian and Ankit Goyal and Danfei Xu and Jonathan Tremblay and Dieter Fox and Jesse Thomason and Animesh Garg},
      year={2022},
      eprint={2209.11302},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2209.11302}, 
}

@article{kuhnlenz2013increasing,
  author = "Kühnlenz, K. and Sosnowski, S. and Buß, M. and others",
  title = "Increasing Helpfulness Towards a Robot by Emotional Adapters for Human-Robot Interaction",
  journal = "International Journal of Social Robotics",
  pages = "485--499",
  year = "2013"
}

@article{lakshika2017understanding,
  author = "Lakshika, Erandi and Barlow, Michael and Easton, Adam",
  title = "Understanding the Interplay of Model Complexity and Fidelity in Multiagent Systems via an Evolutionary Framework",
  journal = "IEEE Transactions on Computational Intelligence and AI in Games",
  volume = "9",
  number = "3",
  pages = "277--289",
  year = "2017"
}

@article{lazaridou2022theoretically,
  author = "Lazaridou, A. and Schrimpf, M. and Rocktaschel, T. and Baroni, M.",
  title = "A Theoretically-Grounded Note on Few-shot Language Coordination",
  journal = "arXiv preprint arXiv:2207.09452",
  year = "2022"
}

@inproceedings{lim2010evolving,
  author = "Lim, C.U. and Baumgarten, R. and Colton, S.",
  title = "Evolving Behaviour Trees for the Commercial Game DEFCON",
  booktitle = "EvoGames 2010: Applications of Evolutionary Computation",
  pages = "100--110",
  year = "2010"
}

@article{liu2023grounding,
  author = "Liu, J. X.",
  title = "Grounding Complex Natural Language Commands for Temporal Tasks in Unseen Environments",
  journal = "arXiv preprint arXiv:2302.11649",
  year = "2023"
}

@article{liu2023reason,
  author = "Liu, Z.",
  title = "Reason for Future, Act for Now: A Principled Framework for Autonomous LLM Agents with Provable Sample Efficiency",
  journal = "arXiv preprint arXiv:2309.17382",
  year = "2023"
}

@misc{huang2022largelanguagemodelsselfimprove,
      title={Large Language Models Can Self-Improve}, 
      author={Jiaxin Huang and Shixiang Shane Gu and Le Hou and Yuexin Wu and Xuezhi Wang and Hongkun Yu and Jiawei Han},
      year={2022},
      eprint={2210.11610},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2210.11610}, 
}



@article{HARNAD1990335,
title = {The symbol grounding problem},
journal = {Physica D: Nonlinear Phenomena},
volume = {42},
number = {1},
pages = {335-346},
year = {1990},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(90)90087-6},
url = {https://www.sciencedirect.com/science/article/pii/0167278990900876},
author = {Stevan Harnad},
abstract = {There has been much discussion recently about the scope and limits of purely symbolic models of the mind and about the proper role of connectionism in cognitive modeling. This paper describes the “symbol grounding problem”: How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) iconic representations, which are analogs of the proximal sensory projections of distal objects and events, and (2) categorical representations, which are learned and innate feature detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) symbolic representations, grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g. “An X is a Y that is Z”). Connectionism is one natural candidate for the mechanism that learns the invariant features underlying categorical representations, thereby connecting names to the proximal projections of the distal objects they stand for. In this way connectionism can be seen as a complementary component in a hybrid nonsymbolic/symbolic model of the mind, rather than a rival to purely symbolic modeling. Such a hybrid model would not have an autonomous symbolic “module,” however; the symbolic functions would emerge as an intrinsically “dedicated” symbol system as a consequence of the bottom-up grounding of categories' names in their sensory representations. Symbol manipulation would be governed not just by the arbitrary shapes of the symbol tokens, but by the nonarbitrary shapes of the icons and category invariants in which they are grounded.}
}

@article{mai2023llm,
  author = "Mai, J.",
  title = "LLM as A Robotic Brain: Unifying Egocentric Memory and Control",
  journal = "arXiv preprint arXiv:2304.09349",
  year = "2023"
}

@article{naveed2024comprehensive,
  author = "Naveed, Humza",
  title = "A Comprehensive Overview of Large Language Models",
  journal = "Journal of Artificial Intelligence Research",
  year = "2024",
  month = "April"
}

@misc{openai2024,
  title = "OpenAI Documentation",
  year = "2024",
  url = "https://www.openai.com/",
  note = "[Online; accessed 2024]"
}

@article{schlegel2013proceedings,
  author = "Schlegel, Christian and Schultz, Ulrik Pagh and Stinckwich, Serge",
  title = "Proceedings of the Third International Workshop on Domain-Specific Languages and Models for Robotic Systems (DSLRob 2012)",
  journal = "arXiv preprint",
  year = "2013"
}

@article{shap2023autonomous,
  author = "Shap, D.",
  title = "Autonomous Agents Are Here: Introducing the ACE Framework",
  journal = "Medium",
  year = "2023"
}

@article{shinn2023reflexion,
  author = "Shinn, N.",
  title = "Reflexion: Language Agents with Verbal Reinforcement Learning",
  journal = "arXiv preprint arXiv:2303.11366",
  year = "2023"
}

@misc{sutton2022bitter,
  author = "Sutton, R.",
  title = "The Bitter Lesson",
  year = "2022",
  url = "http://www.incompleteideas.net/IncIdeas/BitterLesson.html",
  note = "[Online; accessed 2024]"
}

@inproceedings{vaswani2017attention,
  author = "Vaswani, A. and Shazeer, N. and Parmar, N. and others",
  title = "Attention is all you need",
  booktitle = "Advances in Neural Information Processing Systems",
  year = "2017"
}

@article{vemprala2023chatgpt,
  author = "Vemprala, S. and Lin, F. and Manela, S. and others",
  title = "ChatGPT for Robotics: Design Principles and Model Abilities",
  journal = "arXiv preprint arXiv:2306.17582",
  year = "2023"
}

@incollection{wermter2005grounding,
  author = "Wermter, Stefan and Weber, Cornelius and Elshaw, Mark and others",
  title = "Grounding neural robot language in action",
  booktitle = "Lecture Notes in Computer Science",
  pages = "162--181",
  year = "2005"
}

@misc{chen2023frugalgptuselargelanguage,
      title={FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance}, 
      author={Lingjiao Chen and Matei Zaharia and James Zou},
      year={2023},
      eprint={2305.05176},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.05176}, 
}

@article{yang2023plug,
  author = "Yang, Z.",
  title = "Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents",
  journal = "arXiv preprint arXiv:2309.09919v2",
  year = "2023"
}

@article{yang2023dawn,
  author = "Yang, Z.",
  title = "The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)",
  journal = "arXiv preprint arXiv:2309.17421",
  year = "2023"
}

@article{zhang2023large,
  author = "Zhang, B. and Soh, H.",
  title = "Large Language Models as Zero-Shot Human Models for Human-Robot Interaction",
  journal = "arXiv preprint arXiv:2303.03548",
  year = "2023"
}